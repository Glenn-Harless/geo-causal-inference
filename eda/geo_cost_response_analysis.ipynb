{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographic Cost & Response Analysis\n",
    "\n",
    "This notebook joins multiple data sources to create a unified view of marketing spend and user response across different geographic regions.\n",
    "\n",
    "**Data sources:**\n",
    "- GA4 Sessions (response metric)\n",
    "- Meta Geo Spend\n",
    "- TikTok Geo Spend\n",
    "- Google Ads Geo Spend\n",
    "\n",
    "**Target format:**\n",
    "- Date\n",
    "- Geo\n",
    "- Cost (sum of all platform spends)\n",
    "- Response (GA4 sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set paths\n",
    "RAW_DATA_PATH = '../raw_data/'\n",
    "OUTPUT_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection\n",
    "\n",
    "First, let's load all our datasets and examine their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load GA4 Sessions data\n",
    "ga4_sessions = pd.read_csv(os.path.join(RAW_DATA_PATH, 'ga4_sessions.csv'))\n",
    "print(f\"GA4 Sessions shape: {ga4_sessions.shape}\")\n",
    "ga4_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load Meta Geo Spend data\n",
    "meta_geo_spend = pd.read_csv(os.path.join(RAW_DATA_PATH, 'meta_geo_spend.csv'))\n",
    "print(f\"Meta Geo Spend shape: {meta_geo_spend.shape}\")\n",
    "meta_geo_spend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load TikTok Geo Spend data\n",
    "tiktok_geo_spend = pd.read_csv(os.path.join(RAW_DATA_PATH, 'tiktok_geo_spend.csv'))\n",
    "print(f\"TikTok Geo Spend shape: {tiktok_geo_spend.shape}\")\n",
    "tiktok_geo_spend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load Google Ads Geo Spend data\n",
    "gads_geo_spend = pd.read_csv(os.path.join(RAW_DATA_PATH, 'gads_geo_spend.csv'))\n",
    "print(f\"Google Ads Geo Spend shape: {gads_geo_spend.shape}\")\n",
    "gads_geo_spend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing Functions\n",
    "\n",
    "Let's define reusable functions for the key cleaning steps we'll need to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def standardize_date(df, date_col, input_format=None, output_format='%Y-%m-%d'):\n",
    "    \"\"\"\n",
    "    Standardize date format across datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe containing the date column\n",
    "    date_col : str\n",
    "        Name of the date column to standardize\n",
    "    input_format : str, optional\n",
    "        Format of the input date. If None, tries to infer format.\n",
    "    output_format : str, default '%Y-%m-%d'\n",
    "        Desired output date format\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Dataframe with standardized date column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # If input is already datetime, just format it\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[date_col]):\n",
    "        df[date_col] = df[date_col].dt.strftime(output_format)\n",
    "        return df\n",
    "    \n",
    "    # Handle YYYYMMDD format (like in GA4)\n",
    "    if input_format is None and df[date_col].iloc[0].isdigit() and len(str(df[date_col].iloc[0])) == 8:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], format='%Y%m%d')\n",
    "    # Handle M/D/YY format (like in TikTok)\n",
    "    elif input_format is None and '/' in str(df[date_col].iloc[0]):\n",
    "        df[date_col] = pd.to_datetime(df[date_col], format='%m/%d/%y')\n",
    "    # Use specified format or try to infer\n",
    "    else:\n",
    "        if input_format:\n",
    "            df[date_col] = pd.to_datetime(df[date_col], format=input_format)\n",
    "        else:\n",
    "            df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # Convert to output format\n",
    "    df[date_col] = df[date_col].dt.strftime(output_format)\n",
    "    return df\n",
    "\n",
    "def standardize_geo(df, geo_cols, output_col='geo', geo_level='region'):\n",
    "    \"\"\"\n",
    "    Standardize geographic data across datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe containing geo columns\n",
    "    geo_cols : list of str or str\n",
    "        Column name(s) to use for geo standardization\n",
    "    output_col : str, default 'geo'\n",
    "        Name of the standardized output column\n",
    "    geo_level : str, default 'region'\n",
    "        Level of geographic granularity to standardize to ('region', 'city', etc.)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Dataframe with standardized geo column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if isinstance(geo_cols, str):\n",
    "        geo_cols = [geo_cols]\n",
    "    \n",
    "    # Case 1: Use first valid geo column\n",
    "    for col in geo_cols:\n",
    "        if col in df.columns:\n",
    "            df[output_col] = df[col].str.strip() if isinstance(df[col].iloc[0], str) else df[col]\n",
    "            break\n",
    "    \n",
    "    # Standardize names - convert to uppercase for consistent matching\n",
    "    if output_col in df.columns and isinstance(df[output_col].iloc[0], str):\n",
    "        df[output_col] = df[output_col].str.strip().str.upper()\n",
    "        \n",
    "        # Handle special cases\n",
    "        # Replace \"(NOT SET)\" with \"UNKNOWN\"\n",
    "        df[output_col] = df[output_col].replace(r'\\(NOT SET\\)', 'UNKNOWN', regex=True)\n",
    "        \n",
    "        # Remove state/region codes in parentheses if present\n",
    "        df[output_col] = df[output_col].str.replace(r'\\s*\\([A-Z]{2}\\)$', '', regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def standardize_cost(df, cost_col):\n",
    "    \"\"\"\n",
    "    Standardize cost/spend data across datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe containing the cost column\n",
    "    cost_col : str\n",
    "        Column name containing cost data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Dataframe with standardized cost column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure cost column exists\n",
    "    if cost_col not in df.columns:\n",
    "        raise ValueError(f\"Cost column '{cost_col}' not found in dataframe\")\n",
    "    \n",
    "    # Handle string values with currency symbols\n",
    "    if df[cost_col].dtype == 'object':\n",
    "        df[cost_col] = df[cost_col].replace('[\\$,]', '', regex=True)\n",
    "    \n",
    "    # Convert to float\n",
    "    df[cost_col] = pd.to_numeric(df[cost_col], errors='coerce')\n",
    "    \n",
    "    # Fill NaN with 0\n",
    "    df[cost_col] = df[cost_col].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def aggregate_data(df, date_col, geo_col, value_col, agg_func='sum'):\n",
    "    \"\"\"\n",
    "    Aggregate data by date and geo.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe to aggregate\n",
    "    date_col : str\n",
    "        Column name containing date information\n",
    "    geo_col : str\n",
    "        Column name containing geographic information\n",
    "    value_col : str\n",
    "        Column name containing the value to aggregate\n",
    "    agg_func : str or dict, default 'sum'\n",
    "        Aggregation function to apply\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Aggregated dataframe\n",
    "    \"\"\"\n",
    "    return df.groupby([date_col, geo_col])[value_col].agg(agg_func).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process Each Dataset Individually\n",
    "\n",
    "Now let's clean and standardize each dataset separately before joining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process GA4 Sessions data\n",
    "ga4_clean = standardize_date(ga4_sessions, 'Date')\n",
    "ga4_clean = standardize_geo(ga4_clean, ['Region'], 'geo')\n",
    "\n",
    "# Aggregate sessions by date and geo\n",
    "ga4_agg = aggregate_data(ga4_clean, 'Date', 'geo', 'Sessions')\n",
    "ga4_agg = ga4_agg.rename(columns={'Sessions': 'response'})\n",
    "ga4_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process Meta Geo Spend data\n",
    "meta_clean = standardize_date(meta_geo_spend, 'Day')\n",
    "meta_clean = standardize_geo(meta_clean, ['DMA region'], 'geo')\n",
    "meta_clean = standardize_cost(meta_clean, 'Amount spent (USD)')\n",
    "\n",
    "# Aggregate spend by date and geo\n",
    "meta_agg = aggregate_data(meta_clean, 'Day', 'geo', 'Amount spent (USD)')\n",
    "meta_agg = meta_agg.rename(columns={'Day': 'Date', 'Amount spent (USD)': 'meta_cost'})\n",
    "meta_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process TikTok Geo Spend data\n",
    "tiktok_clean = standardize_date(tiktok_geo_spend, 'By Day')\n",
    "tiktok_clean = standardize_geo(tiktok_clean, ['Subregion'], 'geo')\n",
    "tiktok_clean = standardize_cost(tiktok_clean, 'Cost')\n",
    "\n",
    "# Aggregate spend by date and geo\n",
    "tiktok_agg = aggregate_data(tiktok_clean, 'By Day', 'geo', 'Cost')\n",
    "tiktok_agg = tiktok_agg.rename(columns={'By Day': 'Date', 'Cost': 'tiktok_cost'})\n",
    "tiktok_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process Google Ads Geo Spend data\n",
    "gads_clean = standardize_date(gads_geo_spend, 'Day')\n",
    "gads_clean = standardize_geo(gads_clean, ['Region (User location)'], 'geo')\n",
    "gads_clean = standardize_cost(gads_clean, 'Cost')\n",
    "\n",
    "# Aggregate spend by date and geo\n",
    "gads_agg = aggregate_data(gads_clean, 'Day', 'geo', 'Cost')\n",
    "gads_agg = gads_agg.rename(columns={'Day': 'Date', 'Cost': 'gads_cost'})\n",
    "gads_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join All Datasets\n",
    "\n",
    "Now we can join all of our cleaned and standardized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Start with GA4 as the base (response data)\n",
    "combined_df = ga4_agg.copy()\n",
    "\n",
    "# Join with Meta data\n",
    "combined_df = pd.merge(\n",
    "    combined_df, \n",
    "    meta_agg, \n",
    "    on=['Date', 'geo'], \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Join with TikTok data\n",
    "combined_df = pd.merge(\n",
    "    combined_df, \n",
    "    tiktok_agg, \n",
    "    on=['Date', 'geo'], \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Join with Google Ads data\n",
    "combined_df = pd.merge(\n",
    "    combined_df, \n",
    "    gads_agg, \n",
    "    on=['Date', 'geo'], \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0 for cost and response columns\n",
    "cost_cols = ['meta_cost', 'tiktok_cost', 'gads_cost']\n",
    "combined_df[cost_cols] = combined_df[cost_cols].fillna(0)\n",
    "combined_df['response'] = combined_df['response'].fillna(0)\n",
    "\n",
    "# Calculate total cost\n",
    "combined_df['cost'] = combined_df[cost_cols].sum(axis=1)\n",
    "\n",
    "# Sort by date and geo\n",
    "combined_df = combined_df.sort_values(['Date', 'geo'])\n",
    "\n",
    "# Reset index\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "# Preview the final dataset\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic summary statistics\n",
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Checks\n",
    "\n",
    "Let's perform some basic data quality checks on our joined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for records with no response but have costs\n",
    "no_response_with_cost = combined_df[(combined_df['response'] == 0) & (combined_df['cost'] > 0)]\n",
    "print(f\"Records with cost but no response: {len(no_response_with_cost)}\")\n",
    "no_response_with_cost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for records with response but no costs\n",
    "response_no_cost = combined_df[(combined_df['response'] > 0) & (combined_df['cost'] == 0)]\n",
    "print(f\"Records with response but no cost: {len(response_no_cost)}\")\n",
    "response_no_cost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check distribution of costs by platform\n",
    "platform_costs = combined_df[['meta_cost', 'tiktok_cost', 'gads_cost']].sum()\n",
    "platform_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize platform cost distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "platform_costs.plot(kind='bar', color='skyblue')\n",
    "plt.title('Total Cost by Platform')\n",
    "plt.ylabel('Cost (USD)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Additional Analyses\n",
    "\n",
    "Let's explore the relationship between cost and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Scatter plot of cost vs response\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=combined_df, x='cost', y='response', alpha=0.6)\n",
    "plt.title('Cost vs Response')\n",
    "plt.xlabel('Cost (USD)')\n",
    "plt.ylabel('Response (Sessions)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add trend line\n",
    "sns.regplot(data=combined_df, x='cost', y='response', \n",
    "            scatter=False, line_kws={'color': 'red'})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate cost per response by geo\n",
    "# Avoid division by zero\n",
    "combined_df['cost_per_response'] = np.where(\n",
    "    combined_df['response'] > 0,\n",
    "    combined_df['cost'] / combined_df['response'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Aggregate by geo\n",
    "geo_performance = combined_df.groupby('geo').agg({\n",
    "    'cost': 'sum',\n",
    "    'response': 'sum',\n",
    "    'cost_per_response': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate overall CPR\n",
    "geo_performance['overall_cpr'] = geo_performance['cost'] / geo_performance['response']\n",
    "\n",
    "# Sort by cost (descending)\n",
    "geo_performance = geo_performance.sort_values('cost', ascending=False)\n",
    "\n",
    "# Show top 20 geos by spend\n",
    "geo_performance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize top 10 geos by spend\n",
    "top10_geos = geo_performance.head(10)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create bar plot\n",
    "ax = sns.barplot(x='geo', y='cost', data=top10_geos, color='skyblue')\n",
    "\n",
    "# Create a twin axis for response\n",
    "ax2 = ax.twinx()\n",
    "sns.scatterplot(x=np.arange(len(top10_geos)), y='response', data=top10_geos, \n",
    "                color='darkred', s=100, ax=ax2)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_title('Top 10 Geos by Spend')\n",
    "ax.set_xlabel('Geographic Region')\n",
    "ax.set_ylabel('Total Cost (USD)', color='blue')\n",
    "ax2.set_ylabel('Total Response (Sessions)', color='darkred')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Final Dataset\n",
    "\n",
    "Let's save our cleaned and joined dataset for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Save the final dataset\n",
    "combined_df.to_csv(os.path.join(OUTPUT_PATH, 'geo_cost_response_combined.csv'), index=False)\n",
    "print(f\"Final dataset saved to {os.path.join(OUTPUT_PATH, 'geo_cost_response_combined.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps and Recommendations\n",
    "\n",
    "Based on this analysis, here are some potential next steps:\n",
    "\n",
    "1. **Geo Mapping**: Create a more comprehensive geo mapping table to improve the matching between different data sources.\n",
    "2. **Time Lag Analysis**: Investigate the time lag between spend and response to determine the optimal attribution window.\n",
    "3. **Response Curve Modeling**: Model the relationship between spend and response to identify diminishing returns and optimal spend levels.\n",
    "4. **Platform Efficiency**: Compare the cost-effectiveness of different platforms across geos.\n",
    "5. **Anomaly Detection**: Set up automated checks for anomalous data points (e.g., unusually high costs with no response).\n",
    "6. **Data Pipeline**: Implement an automated ETL pipeline for regular updates to this dataset.\n",
    "\n",
    "This analysis provides a foundation for more sophisticated geo-based causal inference analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
